---
title: "Claude 3.7 Sonnet: Anthropic's First Hybrid Model with Extended Thinking"
date: 2025-02-26
draft: false
tags: ["Anthropic", "Claude", "AI", "LLM", "Extended Thinking"]
categories: ["AI", "Technology", "Machine Learning"]
description: "Anthropic releases Claude 3.7 Sonnet, their first hybrid model with extended thinking capabilities, outperforming competitors on key benchmarks while offering flexible thinking controls"
---

# Claude 3.7 Sonnet: Anthropic's First Hybrid Model with Extended Thinking

![Claude 3.7 Sonnet](/posts/claude-3-7-sonnet-extended-thinking/images/claude-3-7-sonnet-extended-thinking-image-1.jpg)

## A New Era of Visible Reasoning

Anthropic has rolled out Claude 3.7 Sonnet – their first hybrid model with extended thinking capabilities. And yes, finally, it can either respond quickly or think step-by-step right before our eyes.

## Benchmark Performance: Simply Stunning

The new Claude's benchmark performance is nothing short of impressive:

![Benchmark Comparisons](/posts/claude-3-7-sonnet-extended-thinking/images/claude-3-7-sonnet-extended-thinking-image-2.jpg)

### Programming Excellence
Claude 3.7 absolutely dominates in programming tasks – achieving **70.3% on SWE-bench** (with custom scaffolding) compared to a mere 48.9% for GPT-4o. That's a massive leap forward!

### Tool Use Mastery
In agent-based tool usage (TAU-bench), Claude is clearly ahead with **81.2% in retail scenarios** (versus 71.5% for Claude 3.5 and 73.5% for GPT-4o). When it comes to following instructions, it's a monster – **93.2% with extended thinking**.

### Mathematical Reasoning
There's an interesting situation with high school mathematics (AIME) – with extended thinking, Claude 3.7 achieves **80%** (compared to 83.3% for GPT-4o), but without it, performance drops to a mere 23.3%. This suggests there's still room for improvement in this area.

## Fine-Grained Thinking Control

![Thinking Controls](/posts/claude-3-7-sonnet-extended-thinking/images/claude-3-7-sonnet-extended-thinking-image-3.jpg)

For API users, Anthropic has added precise control over thinking time – you can specify exactly how many tokens the model will spend on reasoning, up to 128K. This is precisely what was missing in GPT-4o, and it immediately helps balance speed, cost, and quality.

## Claude Code: Terminal-Based Coding

Anthropic has also launched a new tool called Claude Code – a console utility for writing code directly from the terminal (though currently only available in limited preview).

## Attractive Pricing

The pricing structure is quite appealing:
- **$3 per million input tokens**
- **$15 per million output tokens**, including "thinking" tokens

The model is already available on all plans, even the free tier (though without extended thinking capabilities on the free plan).

## What This Means for AI Development

Claude 3.7 Sonnet represents a significant advancement in how AI models can approach complex problems. The extended thinking capability allows users to:

1. **See the reasoning process** in real-time
2. **Control the depth of analysis** based on the task complexity
3. **Balance performance and cost** more effectively
4. **Achieve better results** on complex tasks requiring multi-step reasoning

## Comparison with Competitors

This release positions Anthropic competitively against OpenAI's offerings:

| Feature | Claude 3.7 Sonnet | GPT-4o |
|---------|-------------------|--------|
| Programming (SWE-bench) | 70.3% | 48.9% |
| Tool Use (TAU-bench) | 81.2% | 73.5% |
| Instruction Following | 93.2% | Not specified |
| Math (AIME) | 80% (with thinking) | 83.3% |
| Thinking Control | Fine-grained (up to 128K tokens) | Limited |

## Getting Started

To experience Claude 3.7 Sonnet's extended thinking capabilities, you can access it through:
- [Claude.ai](https://claude.ai) (paid plans)
- Anthropic's API
- Various integrated platforms that support Claude

---

Have you tried Claude 3.7 Sonnet yet? What tasks would you use its extended thinking capabilities for? Share your experiences and ideas in the comments below!
